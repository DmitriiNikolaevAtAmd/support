[20251218 08:37:05][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        1/      50 | consumed samples:          256 | elapsed time per iteration (ms): 87713.3/87713.3 | hip mem usage/free/total/usage_ratio: 89.46GB/102.53GB/191.98GB/46.60% | rocm mem usage/free/total/usage_ratio: 89.94GB/102.04GB/191.98GB/46.85% | throughput per GPU (TFLOP/s/GPU): 33.5/33.5 | tokens per GPU (tokens/s/GPU): 747.2/747.2 | learning rate: 5.000000E-06 | global batch size:   256 | lm loss: 1.204098E+01 | loss scale: 1.0 | grad norm: 3.307 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:11][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        2/      50 | consumed samples:          512 | elapsed time per iteration (ms): 5202.6/46457.9 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | rocm mem usage/free/total/usage_ratio: 95.44GB/96.54GB/191.98GB/49.71% | throughput per GPU (TFLOP/s/GPU): 565.3/299.4 | tokens per GPU (tokens/s/GPU): 12596.8/6672.0 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.204219E+01 | loss scale: 1.0 | grad norm: 3.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:16][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        3/      50 | consumed samples:          768 | elapsed time per iteration (ms): 5014.6/5014.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 586.5/586.5 | tokens per GPU (tokens/s/GPU): 13068.9/13068.9 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.148777E+01 | loss scale: 1.0 | grad norm: 3.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:21][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        4/      50 | consumed samples:         1024 | elapsed time per iteration (ms): 5022.3/5018.5 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 585.6/586.1 | tokens per GPU (tokens/s/GPU): 13048.9/13058.9 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.041016E+01 | loss scale: 1.0 | grad norm: 4.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:26][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        5/      50 | consumed samples:         1280 | elapsed time per iteration (ms): 5032.4/5023.1 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 584.5/585.5 | tokens per GPU (tokens/s/GPU): 13022.7/13046.9 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 9.059455E+00 | loss scale: 1.0 | grad norm: 6.169 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:31][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        6/      50 | consumed samples:         1536 | elapsed time per iteration (ms): 5043.2/5028.2 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 583.2/585.0 | tokens per GPU (tokens/s/GPU): 12994.8/13033.8 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 7.250917E+00 | loss scale: 1.0 | grad norm: 7.152 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:36][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        7/      50 | consumed samples:         1792 | elapsed time per iteration (ms): 5051.7/5032.9 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 582.2/584.4 | tokens per GPU (tokens/s/GPU): 12973.2/13021.7 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 5.908051E+00 | loss scale: 1.0 | grad norm: 7.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:41][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        8/      50 | consumed samples:         2048 | elapsed time per iteration (ms): 5063.1/5037.9 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 580.9/583.8 | tokens per GPU (tokens/s/GPU): 12943.9/13008.7 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 4.241145E+00 | loss scale: 1.0 | grad norm: 7.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:46][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        9/      50 | consumed samples:         2304 | elapsed time per iteration (ms): 5079.2/5043.8 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 579.1/583.1 | tokens per GPU (tokens/s/GPU): 12902.8/12993.6 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.860539E+00 | loss scale: 1.0 | grad norm: 6.179 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:51][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       10/      50 | consumed samples:         2560 | elapsed time per iteration (ms): 5082.7/5048.7 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 578.7/582.6 | tokens per GPU (tokens/s/GPU): 12894.0/12981.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.186695E+00 | loss scale: 1.0 | grad norm: 4.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:37:56][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       11/      50 | consumed samples:         2816 | elapsed time per iteration (ms): 5093.2/5053.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 577.5/582.0 | tokens per GPU (tokens/s/GPU): 12867.3/12968.5 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.600620E+00 | loss scale: 1.0 | grad norm: 3.558 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:01][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       12/      50 | consumed samples:         3072 | elapsed time per iteration (ms): 5095.8/5057.8 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 577.2/581.5 | tokens per GPU (tokens/s/GPU): 12860.9/12957.8 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.124073E+00 | loss scale: 1.0 | grad norm: 2.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:06][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       13/      50 | consumed samples:         3328 | elapsed time per iteration (ms): 5108.0/5062.4 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.8/581.0 | tokens per GPU (tokens/s/GPU): 12830.1/12946.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 9.071150E-01 | loss scale: 1.0 | grad norm: 1.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:11][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       14/      50 | consumed samples:         3584 | elapsed time per iteration (ms): 5114.2/5066.7 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.1/580.5 | tokens per GPU (tokens/s/GPU): 12814.5/12935.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 6.495297E-01 | loss scale: 1.0 | grad norm: 1.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:16][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       15/      50 | consumed samples:         3840 | elapsed time per iteration (ms): 5117.2/5070.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 574.8/580.1 | tokens per GPU (tokens/s/GPU): 12807.1/12925.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 4.634443E-01 | loss scale: 1.0 | grad norm: 1.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:22][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       16/      50 | consumed samples:         4096 | elapsed time per iteration (ms): 5120.3/5074.1 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 574.4/579.7 | tokens per GPU (tokens/s/GPU): 12799.4/12916.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.953719E-01 | loss scale: 1.0 | grad norm: 0.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:27][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       17/      50 | consumed samples:         4352 | elapsed time per iteration (ms): 5127.1/5077.7 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 573.7/579.3 | tokens per GPU (tokens/s/GPU): 12782.2/12907.4 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.515750E-01 | loss scale: 1.0 | grad norm: 0.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:32][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       18/      50 | consumed samples:         4608 | elapsed time per iteration (ms): 5128.7/5080.9 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 573.5/578.9 | tokens per GPU (tokens/s/GPU): 12778.4/12899.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.753721E-01 | loss scale: 1.0 | grad norm: 0.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:37][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       19/      50 | consumed samples:         4864 | elapsed time per iteration (ms): 5127.7/5083.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 573.6/578.6 | tokens per GPU (tokens/s/GPU): 12780.8/12892.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.257071E-01 | loss scale: 1.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:42][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       20/      50 | consumed samples:         5120 | elapsed time per iteration (ms): 5118.8/5085.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 574.6/578.4 | tokens per GPU (tokens/s/GPU): 12803.1/12887.4 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.706159E-01 | loss scale: 1.0 | grad norm: 0.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:48][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       21/      50 | consumed samples:         5376 | elapsed time per iteration (ms): 5426.8/5103.5 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 542.0/576.5 | tokens per GPU (tokens/s/GPU): 12076.3/12844.7 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.904083E-01 | loss scale: 1.0 | grad norm: 0.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:53][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       22/      50 | consumed samples:         5632 | elapsed time per iteration (ms): 5400.2/5118.4 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 544.7/574.9 | tokens per GPU (tokens/s/GPU): 12135.8/12809.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.437280E-01 | loss scale: 1.0 | grad norm: 0.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:38:59][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       23/      50 | consumed samples:         5888 | elapsed time per iteration (ms): 6296.9/5174.5 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 467.1/569.7 | tokens per GPU (tokens/s/GPU): 10407.6/12694.9 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.198699E-01 | loss scale: 1.0 | grad norm: 0.248 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:05][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       24/      50 | consumed samples:         6144 | elapsed time per iteration (ms): 5402.2/5184.8 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 544.4/568.6 | tokens per GPU (tokens/s/GPU): 12131.3/12669.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.052888E-01 | loss scale: 1.0 | grad norm: 0.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:10][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       25/      50 | consumed samples:         6400 | elapsed time per iteration (ms): 5110.1/5181.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.6/568.9 | tokens per GPU (tokens/s/GPU): 12824.9/12676.0 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.058560E-01 | loss scale: 1.0 | grad norm: 0.247 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:15][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       26/      50 | consumed samples:         6656 | elapsed time per iteration (ms): 5114.1/5178.8 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.1/569.2 | tokens per GPU (tokens/s/GPU): 12814.8/12681.8 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 8.840220E-02 | loss scale: 1.0 | grad norm: 0.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:20][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       27/      50 | consumed samples:         6912 | elapsed time per iteration (ms): 5114.9/5176.2 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.0/569.4 | tokens per GPU (tokens/s/GPU): 12812.7/12687.1 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 7.957634E-02 | loss scale: 1.0 | grad norm: 0.182 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:25][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       28/      50 | consumed samples:         7168 | elapsed time per iteration (ms): 5106.6/5173.5 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.0/569.6 | tokens per GPU (tokens/s/GPU): 12833.6/12692.7 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 7.899091E-02 | loss scale: 1.0 | grad norm: 0.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:30][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       29/      50 | consumed samples:         7424 | elapsed time per iteration (ms): 5106.9/5171.1 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.9/569.9 | tokens per GPU (tokens/s/GPU): 12832.9/12697.9 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 6.544290E-02 | loss scale: 1.0 | grad norm: 0.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:35][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       30/      50 | consumed samples:         7680 | elapsed time per iteration (ms): 5104.0/5168.7 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.3/570.1 | tokens per GPU (tokens/s/GPU): 12840.0/12703.0 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 6.245424E-02 | loss scale: 1.0 | grad norm: 0.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:40][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       31/      50 | consumed samples:         7936 | elapsed time per iteration (ms): 5111.1/5166.7 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.5/570.3 | tokens per GPU (tokens/s/GPU): 12822.3/12707.1 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 6.245676E-02 | loss scale: 1.0 | grad norm: 0.154 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:45][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       32/      50 | consumed samples:         8192 | elapsed time per iteration (ms): 5106.7/5164.7 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.0/570.5 | tokens per GPU (tokens/s/GPU): 12833.2/12711.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 5.344947E-02 | loss scale: 1.0 | grad norm: 0.141 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:51][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       33/      50 | consumed samples:         8448 | elapsed time per iteration (ms): 5105.9/5162.8 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.0/570.7 | tokens per GPU (tokens/s/GPU): 12835.3/12715.3 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 5.024122E-02 | loss scale: 1.0 | grad norm: 0.136 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:39:56][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       34/      50 | consumed samples:         8704 | elapsed time per iteration (ms): 5106.0/5161.0 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.0/570.8 | tokens per GPU (tokens/s/GPU): 12835.1/12719.0 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 4.657329E-02 | loss scale: 1.0 | grad norm: 0.132 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:01][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       35/      50 | consumed samples:         8960 | elapsed time per iteration (ms): 5110.0/5159.5 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.6/571.0 | tokens per GPU (tokens/s/GPU): 12825.1/12722.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 4.374465E-02 | loss scale: 1.0 | grad norm: 0.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:06][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       36/      50 | consumed samples:         9216 | elapsed time per iteration (ms): 5110.9/5158.0 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.5/571.1 | tokens per GPU (tokens/s/GPU): 12822.8/12725.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.898568E-02 | loss scale: 1.0 | grad norm: 0.117 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:11][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       37/      50 | consumed samples:         9472 | elapsed time per iteration (ms): 5107.9/5156.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.8/571.2 | tokens per GPU (tokens/s/GPU): 12830.3/12728.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.813941E-02 | loss scale: 1.0 | grad norm: 0.115 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:16][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       38/      50 | consumed samples:         9728 | elapsed time per iteration (ms): 5107.9/5155.3 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.8/571.4 | tokens per GPU (tokens/s/GPU): 12830.2/12731.0 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.752861E-02 | loss scale: 1.0 | grad norm: 0.120 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:21][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       39/      50 | consumed samples:         9984 | elapsed time per iteration (ms): 5108.3/5154.0 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.8/571.5 | tokens per GPU (tokens/s/GPU): 12829.4/12733.7 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.345628E-02 | loss scale: 1.0 | grad norm: 0.107 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:26][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       40/      50 | consumed samples:        10240 | elapsed time per iteration (ms): 5102.3/5152.6 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.5/571.6 | tokens per GPU (tokens/s/GPU): 12844.4/12736.6 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.246421E-02 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:31][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       41/      50 | consumed samples:        10496 | elapsed time per iteration (ms): 5101.6/5151.3 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.5/571.7 | tokens per GPU (tokens/s/GPU): 12846.1/12739.4 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 3.038107E-02 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:37][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       42/      50 | consumed samples:        10752 | elapsed time per iteration (ms): 5103.5/5150.1 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.3/571.9 | tokens per GPU (tokens/s/GPU): 12841.3/12742.0 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.976460E-02 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:42][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       43/      50 | consumed samples:        11008 | elapsed time per iteration (ms): 5101.9/5149.0 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.5/572.0 | tokens per GPU (tokens/s/GPU): 12845.3/12744.5 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.775801E-02 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:47][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       44/      50 | consumed samples:        11264 | elapsed time per iteration (ms): 5101.4/5147.8 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.6/572.1 | tokens per GPU (tokens/s/GPU): 12846.7/12746.9 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.531127E-02 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:52][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       45/      50 | consumed samples:        11520 | elapsed time per iteration (ms): 5102.2/5146.8 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.5/572.2 | tokens per GPU (tokens/s/GPU): 12844.7/12749.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.348977E-02 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:40:57][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       46/      50 | consumed samples:        11776 | elapsed time per iteration (ms): 5107.8/5145.9 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 575.8/572.3 | tokens per GPU (tokens/s/GPU): 12830.6/12751.0 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.258862E-02 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:41:02][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       47/      50 | consumed samples:        12032 | elapsed time per iteration (ms): 5100.6/5144.9 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.6/572.4 | tokens per GPU (tokens/s/GPU): 12848.8/12753.2 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.296929E-02 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:41:07][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       48/      50 | consumed samples:        12288 | elapsed time per iteration (ms): 5098.2/5143.9 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 576.9/572.5 | tokens per GPU (tokens/s/GPU): 12854.7/12755.4 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.079840E-02 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:41:13][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       49/      50 | consumed samples:        12544 | elapsed time per iteration (ms): 5390.4/5149.1 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 545.6/571.9 | tokens per GPU (tokens/s/GPU): 12157.9/12742.7 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 2.069005E-02 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251218 08:41:18][root/amd][pre_trainer][ip-10.21.9.25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       50/      50 | consumed samples:        12800 | elapsed time per iteration (ms): 5240.1/5151.0 | hip mem usage/free/total/usage_ratio: 94.95GB/97.03GB/191.98GB/49.46% | throughput per GPU (TFLOP/s/GPU): 561.3/571.7 | tokens per GPU (tokens/s/GPU): 12506.7/12737.8 | learning rate: 1.000000E-05 | global batch size:   256 | lm loss: 1.820078E-02 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
