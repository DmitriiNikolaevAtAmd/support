[20251211 08:23:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        2/      50 | consumed samples:         1024 | elapsed time per iteration (ms): 8622.8/53069.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | rocm mem usage/free/total/usage_ratio: 115.27GB/76.71GB/191.98GB/60.04% | throughput per GPU (TFLOP/s/GPU): 682.2/371.3 | tokens per GPU (tokens/s/GPU): 15200.6/8272.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.204180E+01 | loss scale: 1.0 | grad norm: 2.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:23:21][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        3/      50 | consumed samples:         1536 | elapsed time per iteration (ms): 8435.7/8435.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 697.3/697.3 | tokens per GPU (tokens/s/GPU): 15537.7/15537.7 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.169232E+01 | loss scale: 1.0 | grad norm: 2.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:23:29][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        4/      50 | consumed samples:         2048 | elapsed time per iteration (ms): 8466.1/8450.9 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 694.8/696.1 | tokens per GPU (tokens/s/GPU): 15482.0/15509.9 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.104992E+01 | loss scale: 1.0 | grad norm: 2.752 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:23:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        5/      50 | consumed samples:         2560 | elapsed time per iteration (ms): 8489.4/8463.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 692.9/695.0 | tokens per GPU (tokens/s/GPU): 15439.5/15486.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.051200E+01 | loss scale: 1.0 | grad norm: 3.171 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:23:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        6/      50 | consumed samples:         3072 | elapsed time per iteration (ms): 8513.1/8476.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 691.0/694.0 | tokens per GPU (tokens/s/GPU): 15396.5/15463.9 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 9.949954E+00 | loss scale: 1.0 | grad norm: 4.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:23:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        7/      50 | consumed samples:         3584 | elapsed time per iteration (ms): 8549.4/8490.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.1/692.8 | tokens per GPU (tokens/s/GPU): 15331.1/15437.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 9.351795E+00 | loss scale: 1.0 | grad norm: 4.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:24:03][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        8/      50 | consumed samples:         4096 | elapsed time per iteration (ms): 8559.3/8502.2 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.3/691.9 | tokens per GPU (tokens/s/GPU): 15313.3/15416.7 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 8.795235E+00 | loss scale: 1.0 | grad norm: 4.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:24:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        9/      50 | consumed samples:         4608 | elapsed time per iteration (ms): 8568.9/8511.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.5/691.1 | tokens per GPU (tokens/s/GPU): 15296.3/15399.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 8.221826E+00 | loss scale: 1.0 | grad norm: 5.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:24:20][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       10/      50 | consumed samples:         5120 | elapsed time per iteration (ms): 8589.7/8521.5 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 684.8/690.3 | tokens per GPU (tokens/s/GPU): 15259.1/15381.9 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 7.723904E+00 | loss scale: 1.0 | grad norm: 5.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:24:29][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       11/      50 | consumed samples:         5632 | elapsed time per iteration (ms): 8584.0/8528.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 685.3/689.8 | tokens per GPU (tokens/s/GPU): 15269.3/15369.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 7.170630E+00 | loss scale: 1.0 | grad norm: 5.151 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:24:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       12/      50 | consumed samples:         6144 | elapsed time per iteration (ms): 8587.6/8534.3 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 685.0/689.3 | tokens per GPU (tokens/s/GPU): 15263.0/15358.8 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 6.692392E+00 | loss scale: 1.0 | grad norm: 5.575 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:24:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       13/      50 | consumed samples:         6656 | elapsed time per iteration (ms): 8585.7/8539.0 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 685.1/688.9 | tokens per GPU (tokens/s/GPU): 15266.3/15350.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 6.309946E+00 | loss scale: 1.0 | grad norm: 5.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:24:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       14/      50 | consumed samples:         7168 | elapsed time per iteration (ms): 8579.5/8542.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 685.6/688.6 | tokens per GPU (tokens/s/GPU): 15277.3/15344.3 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 5.925191E+00 | loss scale: 1.0 | grad norm: 6.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:25:03][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       15/      50 | consumed samples:         7680 | elapsed time per iteration (ms): 8574.0/8544.8 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.1/688.5 | tokens per GPU (tokens/s/GPU): 15287.2/15339.9 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 5.404014E+00 | loss scale: 1.0 | grad norm: 6.370 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:25:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       16/      50 | consumed samples:         8192 | elapsed time per iteration (ms): 8584.6/8547.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 685.2/688.2 | tokens per GPU (tokens/s/GPU): 15268.3/15334.8 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 5.075763E+00 | loss scale: 1.0 | grad norm: 6.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:25:21][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       17/      50 | consumed samples:         8704 | elapsed time per iteration (ms): 8568.1/8549.0 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.6/688.1 | tokens per GPU (tokens/s/GPU): 15297.7/15332.3 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 4.679021E+00 | loss scale: 1.0 | grad norm: 7.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:25:29][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       18/      50 | consumed samples:         9216 | elapsed time per iteration (ms): 8567.9/8550.2 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.6/688.0 | tokens per GPU (tokens/s/GPU): 15298.1/15330.2 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 4.481799E+00 | loss scale: 1.0 | grad norm: 7.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:25:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       19/      50 | consumed samples:         9728 | elapsed time per iteration (ms): 8692.2/8558.5 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 676.8/687.4 | tokens per GPU (tokens/s/GPU): 15079.2/15315.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 4.218342E+00 | loss scale: 1.0 | grad norm: 8.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:25:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       20/      50 | consumed samples:        10240 | elapsed time per iteration (ms): 8661.2/8564.2 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 679.2/686.9 | tokens per GPU (tokens/s/GPU): 15133.3/15305.3 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 4.004100E+00 | loss scale: 1.0 | grad norm: 9.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:25:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       21/      50 | consumed samples:        10752 | elapsed time per iteration (ms): 8668.4/8569.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 678.6/686.5 | tokens per GPU (tokens/s/GPU): 15120.6/15295.6 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 3.682219E+00 | loss scale: 1.0 | grad norm: 9.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:26:04][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       22/      50 | consumed samples:        11264 | elapsed time per iteration (ms): 8577.7/8570.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 685.8/686.4 | tokens per GPU (tokens/s/GPU): 15280.6/15294.8 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 3.532671E+00 | loss scale: 1.0 | grad norm: 10.406 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:26:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       23/      50 | consumed samples:        11776 | elapsed time per iteration (ms): 8653.9/8574.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 679.8/686.1 | tokens per GPU (tokens/s/GPU): 15146.0/15287.7 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 3.415569E+00 | loss scale: 1.0 | grad norm: 9.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:26:21][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       24/      50 | consumed samples:        12288 | elapsed time per iteration (ms): 8558.9/8573.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.3/686.2 | tokens per GPU (tokens/s/GPU): 15314.1/15288.9 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 3.110532E+00 | loss scale: 1.0 | grad norm: 10.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:26:29][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       25/      50 | consumed samples:        12800 | elapsed time per iteration (ms): 8563.6/8573.0 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.9/686.2 | tokens per GPU (tokens/s/GPU): 15305.7/15289.7 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 3.099723E+00 | loss scale: 1.0 | grad norm: 9.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:26:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       26/      50 | consumed samples:        13312 | elapsed time per iteration (ms): 8558.9/8572.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.3/686.2 | tokens per GPU (tokens/s/GPU): 15314.2/15290.7 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 2.717672E+00 | loss scale: 1.0 | grad norm: 10.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:26:47][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       27/      50 | consumed samples:        13824 | elapsed time per iteration (ms): 8549.2/8571.5 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.1/686.3 | tokens per GPU (tokens/s/GPU): 15331.6/15292.3 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 2.665202E+00 | loss scale: 1.0 | grad norm: 10.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:26:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       28/      50 | consumed samples:        14336 | elapsed time per iteration (ms): 8569.0/8571.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.5/686.3 | tokens per GPU (tokens/s/GPU): 15296.1/15292.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 2.499527E+00 | loss scale: 1.0 | grad norm: 11.548 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:27:04][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       29/      50 | consumed samples:        14848 | elapsed time per iteration (ms): 8546.0/8570.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.3/686.4 | tokens per GPU (tokens/s/GPU): 15337.1/15294.1 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 2.276470E+00 | loss scale: 1.0 | grad norm: 11.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:27:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       30/      50 | consumed samples:        15360 | elapsed time per iteration (ms): 8555.9/8569.9 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.5/686.4 | tokens per GPU (tokens/s/GPU): 15319.4/15295.0 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 2.163308E+00 | loss scale: 1.0 | grad norm: 12.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:27:21][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       31/      50 | consumed samples:        15872 | elapsed time per iteration (ms): 8549.9/8569.2 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.0/686.5 | tokens per GPU (tokens/s/GPU): 15330.2/15296.2 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 2.092703E+00 | loss scale: 1.0 | grad norm: 13.359 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:27:29][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       32/      50 | consumed samples:        16384 | elapsed time per iteration (ms): 8546.4/8568.5 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.3/686.6 | tokens per GPU (tokens/s/GPU): 15336.6/15297.6 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.898102E+00 | loss scale: 1.0 | grad norm: 13.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:27:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       33/      50 | consumed samples:        16896 | elapsed time per iteration (ms): 8553.8/8568.0 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.7/686.6 | tokens per GPU (tokens/s/GPU): 15323.2/15298.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.898032E+00 | loss scale: 1.0 | grad norm: 12.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:27:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       34/      50 | consumed samples:        17408 | elapsed time per iteration (ms): 8548.1/8567.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.2/686.6 | tokens per GPU (tokens/s/GPU): 15333.5/15299.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.774338E+00 | loss scale: 1.0 | grad norm: 10.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:27:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       35/      50 | consumed samples:        17920 | elapsed time per iteration (ms): 8544.1/8566.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.5/686.7 | tokens per GPU (tokens/s/GPU): 15340.7/15300.8 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.671849E+00 | loss scale: 1.0 | grad norm: 11.330 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:28:04][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       36/      50 | consumed samples:        18432 | elapsed time per iteration (ms): 8550.6/8566.2 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.0/686.7 | tokens per GPU (tokens/s/GPU): 15329.0/15301.6 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.432718E+00 | loss scale: 1.0 | grad norm: 8.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:28:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       37/      50 | consumed samples:        18944 | elapsed time per iteration (ms): 8548.9/8565.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.1/686.8 | tokens per GPU (tokens/s/GPU): 15332.0/15302.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.592135E+00 | loss scale: 1.0 | grad norm: 9.295 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:28:21][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       38/      50 | consumed samples:        19456 | elapsed time per iteration (ms): 8545.5/8565.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.4/686.8 | tokens per GPU (tokens/s/GPU): 15338.1/15303.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.451793E+00 | loss scale: 1.0 | grad norm: 8.227 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:28:29][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       39/      50 | consumed samples:        19968 | elapsed time per iteration (ms): 8542.0/8564.5 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.7/686.9 | tokens per GPU (tokens/s/GPU): 15344.4/15304.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.420744E+00 | loss scale: 1.0 | grad norm: 8.189 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:28:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       40/      50 | consumed samples:        20480 | elapsed time per iteration (ms): 8552.1/8564.2 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.8/686.9 | tokens per GPU (tokens/s/GPU): 15326.4/15305.1 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.341631E+00 | loss scale: 1.0 | grad norm: 7.360 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:28:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       41/      50 | consumed samples:        20992 | elapsed time per iteration (ms): 8547.7/8563.8 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.2/686.9 | tokens per GPU (tokens/s/GPU): 15334.2/15305.9 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.381004E+00 | loss scale: 1.0 | grad norm: 7.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:28:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       42/      50 | consumed samples:        21504 | elapsed time per iteration (ms): 8550.2/8563.4 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.0/686.9 | tokens per GPU (tokens/s/GPU): 15329.8/15306.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.248708E+00 | loss scale: 1.0 | grad norm: 6.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:29:03][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       43/      50 | consumed samples:        22016 | elapsed time per iteration (ms): 8548.4/8563.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 688.1/687.0 | tokens per GPU (tokens/s/GPU): 15332.9/15307.1 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.157130E+00 | loss scale: 1.0 | grad norm: 5.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:29:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       44/      50 | consumed samples:        22528 | elapsed time per iteration (ms): 8553.6/8562.8 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.7/687.0 | tokens per GPU (tokens/s/GPU): 15323.6/15307.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 1.057545E+00 | loss scale: 1.0 | grad norm: 4.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:29:20][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       45/      50 | consumed samples:        23040 | elapsed time per iteration (ms): 8554.7/8562.6 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 687.6/687.0 | tokens per GPU (tokens/s/GPU): 15321.6/15307.8 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 9.830279E-01 | loss scale: 1.0 | grad norm: 4.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:29:29][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       46/      50 | consumed samples:        23552 | elapsed time per iteration (ms): 8566.5/8562.7 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.7/687.0 | tokens per GPU (tokens/s/GPU): 15300.4/15307.7 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 9.813195E-01 | loss scale: 1.0 | grad norm: 4.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:29:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       47/      50 | consumed samples:        24064 | elapsed time per iteration (ms): 8568.1/8562.9 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.6/687.0 | tokens per GPU (tokens/s/GPU): 15297.6/15307.4 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 9.093763E-01 | loss scale: 1.0 | grad norm: 4.281 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:29:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       48/      50 | consumed samples:        24576 | elapsed time per iteration (ms): 8567.8/8563.0 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.6/687.0 | tokens per GPU (tokens/s/GPU): 15298.2/15307.2 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 7.853141E-01 | loss scale: 1.0 | grad norm: 3.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:29:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       49/      50 | consumed samples:        25088 | elapsed time per iteration (ms): 8661.9/8565.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 679.1/686.8 | tokens per GPU (tokens/s/GPU): 15131.9/15303.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 7.825383E-01 | loss scale: 1.0 | grad norm: 3.299 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:30:03][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       50/      50 | consumed samples:        25600 | elapsed time per iteration (ms): 8564.4/8565.1 | hip mem usage/free/total/usage_ratio: 114.79GB/77.20GB/191.98GB/59.79% | throughput per GPU (TFLOP/s/GPU): 686.9/686.8 | tokens per GPU (tokens/s/GPU): 15304.4/15303.5 | learning rate: 1.000000E-05 | global batch size:   512 | lm loss: 7.533884E-01 | loss scale: 1.0 | grad norm: 2.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:30:03][rank-0/8][DEBUG] [-----------utils.py:385] : [after training is done] datetime: 2025-12-11 08:30:03 
[NODE-0(tw030)] [INFO] primus launcher exited with code 0