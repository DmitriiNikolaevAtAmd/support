[20251211 08:38:38][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        2/      50 | consumed samples:          256 | elapsed time per iteration (ms): 9898.7/21891.9 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | rocm mem usage/free/total/usage_ratio: 118.18GB/73.81GB/191.98GB/61.56% | throughput per GPU (TFLOP/s/GPU): 766.8/495.4 | tokens per GPU (tokens/s/GPU): 13241.3/8554.7 | learning rate: 1.000000E-05 | global batch size:   128 | lm loss: 1.189804E+01 | loss scale: 1.0 | grad norm: 2.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:38:48][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        3/      50 | consumed samples:          384 | elapsed time per iteration (ms): 9707.0/9707.0 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 782.0/782.0 | tokens per GPU (tokens/s/GPU): 13502.9/13502.9 | learning rate: 9.989295E-06 | global batch size:   128 | lm loss: 1.155258E+01 | loss scale: 1.0 | grad norm: 2.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:38:57][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        4/      50 | consumed samples:          512 | elapsed time per iteration (ms): 9759.5/9733.3 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 777.8/779.9 | tokens per GPU (tokens/s/GPU): 13430.1/13466.5 | learning rate: 9.957224E-06 | global batch size:   128 | lm loss: 1.098099E+01 | loss scale: 1.0 | grad norm: 3.567 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:39:07][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        5/      50 | consumed samples:          640 | elapsed time per iteration (ms): 9776.3/9747.6 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 776.4/778.7 | tokens per GPU (tokens/s/GPU): 13407.1/13446.7 | learning rate: 9.903926E-06 | global batch size:   128 | lm loss: 1.057484E+01 | loss scale: 1.0 | grad norm: 4.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:39:17][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        6/      50 | consumed samples:          768 | elapsed time per iteration (ms): 9812.6/9763.8 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 773.6/777.4 | tokens per GPU (tokens/s/GPU): 13357.6/13424.4 | learning rate: 9.829630E-06 | global batch size:   128 | lm loss: 1.023579E+01 | loss scale: 1.0 | grad norm: 6.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:39:27][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        7/      50 | consumed samples:          896 | elapsed time per iteration (ms): 9856.0/9782.3 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.2/776.0 | tokens per GPU (tokens/s/GPU): 13298.6/13399.3 | learning rate: 9.734651E-06 | global batch size:   128 | lm loss: 9.779916E+00 | loss scale: 1.0 | grad norm: 8.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:39:37][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        8/      50 | consumed samples:         1024 | elapsed time per iteration (ms): 9869.2/9796.8 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.1/774.8 | tokens per GPU (tokens/s/GPU): 13280.9/13379.5 | learning rate: 9.619398E-06 | global batch size:   128 | lm loss: 9.292701E+00 | loss scale: 1.0 | grad norm: 9.561 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:39:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration        9/      50 | consumed samples:         1152 | elapsed time per iteration (ms): 9898.0/9811.2 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 766.9/773.7 | tokens per GPU (tokens/s/GPU): 13242.3/13359.9 | learning rate: 9.484364E-06 | global batch size:   128 | lm loss: 8.711916E+00 | loss scale: 1.0 | grad norm: 9.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:39:57][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       10/      50 | consumed samples:         1280 | elapsed time per iteration (ms): 10134.1/9851.6 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 749.0/770.6 | tokens per GPU (tokens/s/GPU): 12933.8/13306.7 | learning rate: 9.330127E-06 | global batch size:   128 | lm loss: 8.257510E+00 | loss scale: 1.0 | grad norm: 9.167 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:40:07][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       11/      50 | consumed samples:         1408 | elapsed time per iteration (ms): 10351.5/9907.1 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 733.3/766.5 | tokens per GPU (tokens/s/GPU): 12662.1/13235.0 | learning rate: 9.157348E-06 | global batch size:   128 | lm loss: 7.868680E+00 | loss scale: 1.0 | grad norm: 8.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:40:17][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       12/      50 | consumed samples:         1536 | elapsed time per iteration (ms): 9908.5/9907.3 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 766.1/766.4 | tokens per GPU (tokens/s/GPU): 13228.2/13234.4 | learning rate: 8.966766E-06 | global batch size:   128 | lm loss: 7.523456E+00 | loss scale: 1.0 | grad norm: 8.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:40:27][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       13/      50 | consumed samples:         1664 | elapsed time per iteration (ms): 9895.0/9906.2 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 767.1/766.5 | tokens per GPU (tokens/s/GPU): 13246.3/13235.5 | learning rate: 8.759199E-06 | global batch size:   128 | lm loss: 7.298280E+00 | loss scale: 1.0 | grad norm: 9.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:40:37][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       14/      50 | consumed samples:         1792 | elapsed time per iteration (ms): 9901.8/9905.8 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 766.6/766.5 | tokens per GPU (tokens/s/GPU): 13237.2/13235.6 | learning rate: 8.535534E-06 | global batch size:   128 | lm loss: 6.939137E+00 | loss scale: 1.0 | grad norm: 10.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:40:47][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       15/      50 | consumed samples:         1920 | elapsed time per iteration (ms): 9878.5/9903.7 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 768.4/766.7 | tokens per GPU (tokens/s/GPU): 13268.4/13238.1 | learning rate: 8.296729E-06 | global batch size:   128 | lm loss: 6.742017E+00 | loss scale: 1.0 | grad norm: 11.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:40:56][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       16/      50 | consumed samples:         2048 | elapsed time per iteration (ms): 9879.7/9902.0 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 768.3/766.8 | tokens per GPU (tokens/s/GPU): 13266.8/13240.2 | learning rate: 8.043807E-06 | global batch size:   128 | lm loss: 6.520791E+00 | loss scale: 1.0 | grad norm: 12.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:41:06][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       17/      50 | consumed samples:         2176 | elapsed time per iteration (ms): 9879.4/9900.5 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 768.3/766.9 | tokens per GPU (tokens/s/GPU): 13267.2/13242.0 | learning rate: 7.777851E-06 | global batch size:   128 | lm loss: 6.271520E+00 | loss scale: 1.0 | grad norm: 14.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:41:16][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       18/      50 | consumed samples:         2304 | elapsed time per iteration (ms): 9870.5/9898.6 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.0/767.0 | tokens per GPU (tokens/s/GPU): 13279.1/13244.3 | learning rate: 7.500000E-06 | global batch size:   128 | lm loss: 6.153078E+00 | loss scale: 1.0 | grad norm: 15.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:41:26][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       19/      50 | consumed samples:         2432 | elapsed time per iteration (ms): 9870.2/9896.9 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.1/767.1 | tokens per GPU (tokens/s/GPU): 13279.5/13246.4 | learning rate: 7.211444E-06 | global batch size:   128 | lm loss: 5.900342E+00 | loss scale: 1.0 | grad norm: 17.384 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:41:36][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       20/      50 | consumed samples:         2560 | elapsed time per iteration (ms): 9869.1/9895.4 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.1/767.2 | tokens per GPU (tokens/s/GPU): 13281.0/13248.3 | learning rate: 6.913417E-06 | global batch size:   128 | lm loss: 5.891515E+00 | loss scale: 1.0 | grad norm: 18.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:41:46][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       21/      50 | consumed samples:         2688 | elapsed time per iteration (ms): 9859.8/9893.5 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.9/767.4 | tokens per GPU (tokens/s/GPU): 13293.5/13250.7 | learning rate: 6.607198E-06 | global batch size:   128 | lm loss: 5.799142E+00 | loss scale: 1.0 | grad norm: 19.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:41:56][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       22/      50 | consumed samples:         2816 | elapsed time per iteration (ms): 9862.6/9892.0 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.7/767.5 | tokens per GPU (tokens/s/GPU): 13289.8/13252.6 | learning rate: 6.294095E-06 | global batch size:   128 | lm loss: 5.681195E+00 | loss scale: 1.0 | grad norm: 22.366 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:42:06][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       23/      50 | consumed samples:         2944 | elapsed time per iteration (ms): 9855.0/9890.2 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.2/767.6 | tokens per GPU (tokens/s/GPU): 13300.1/13254.9 | learning rate: 5.975452E-06 | global batch size:   128 | lm loss: 5.511645E+00 | loss scale: 1.0 | grad norm: 23.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:42:15][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       24/      50 | consumed samples:         3072 | elapsed time per iteration (ms): 9861.5/9888.9 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.7/767.7 | tokens per GPU (tokens/s/GPU): 13291.2/13256.5 | learning rate: 5.652631E-06 | global batch size:   128 | lm loss: 5.355567E+00 | loss scale: 1.0 | grad norm: 25.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:42:25][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       25/      50 | consumed samples:         3200 | elapsed time per iteration (ms): 9886.1/9888.8 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 767.8/767.7 | tokens per GPU (tokens/s/GPU): 13258.2/13256.6 | learning rate: 5.327016E-06 | global batch size:   128 | lm loss: 5.334930E+00 | loss scale: 1.0 | grad norm: 27.115 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:42:35][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       26/      50 | consumed samples:         3328 | elapsed time per iteration (ms): 9837.2/9886.6 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 771.6/767.9 | tokens per GPU (tokens/s/GPU): 13324.1/13259.4 | learning rate: 5.000000E-06 | global batch size:   128 | lm loss: 5.208381E+00 | loss scale: 1.0 | grad norm: 26.208 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:42:45][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       27/      50 | consumed samples:         3456 | elapsed time per iteration (ms): 9850.9/9885.2 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.6/768.0 | tokens per GPU (tokens/s/GPU): 13305.6/13261.3 | learning rate: 4.672984E-06 | global batch size:   128 | lm loss: 5.183990E+00 | loss scale: 1.0 | grad norm: 28.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:42:55][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       28/      50 | consumed samples:         3584 | elapsed time per iteration (ms): 9831.9/9883.2 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 772.1/768.2 | tokens per GPU (tokens/s/GPU): 13331.3/13264.0 | learning rate: 4.347369E-06 | global batch size:   128 | lm loss: 4.865314E+00 | loss scale: 1.0 | grad norm: 29.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:43:05][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       29/      50 | consumed samples:         3712 | elapsed time per iteration (ms): 9835.1/9881.4 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 771.8/768.3 | tokens per GPU (tokens/s/GPU): 13327.0/13266.3 | learning rate: 4.024549E-06 | global batch size:   128 | lm loss: 4.795079E+00 | loss scale: 1.0 | grad norm: 31.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:43:14][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       30/      50 | consumed samples:         3840 | elapsed time per iteration (ms): 9836.6/9879.8 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 771.7/768.4 | tokens per GPU (tokens/s/GPU): 13325.0/13268.4 | learning rate: 3.705905E-06 | global batch size:   128 | lm loss: 4.616974E+00 | loss scale: 1.0 | grad norm: 29.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:43:24][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       31/      50 | consumed samples:         3968 | elapsed time per iteration (ms): 9845.9/9878.6 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 771.0/768.5 | tokens per GPU (tokens/s/GPU): 13312.3/13269.9 | learning rate: 3.392803E-06 | global batch size:   128 | lm loss: 4.491116E+00 | loss scale: 1.0 | grad norm: 30.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:43:34][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       32/      50 | consumed samples:         4096 | elapsed time per iteration (ms): 9853.6/9877.8 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.4/768.6 | tokens per GPU (tokens/s/GPU): 13301.9/13271.0 | learning rate: 3.086583E-06 | global batch size:   128 | lm loss: 4.216515E+00 | loss scale: 1.0 | grad norm: 29.182 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:43:44][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       33/      50 | consumed samples:         4224 | elapsed time per iteration (ms): 9843.9/9876.7 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 771.1/768.6 | tokens per GPU (tokens/s/GPU): 13315.1/13272.4 | learning rate: 2.788556E-06 | global batch size:   128 | lm loss: 4.074965E+00 | loss scale: 1.0 | grad norm: 26.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:43:54][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       34/      50 | consumed samples:         4352 | elapsed time per iteration (ms): 9850.5/9875.9 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.6/768.7 | tokens per GPU (tokens/s/GPU): 13306.1/13273.5 | learning rate: 2.500000E-06 | global batch size:   128 | lm loss: 3.900817E+00 | loss scale: 1.0 | grad norm: 26.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:44:04][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       35/      50 | consumed samples:         4480 | elapsed time per iteration (ms): 9857.2/9875.3 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.1/768.7 | tokens per GPU (tokens/s/GPU): 13297.1/13274.2 | learning rate: 2.222149E-06 | global batch size:   128 | lm loss: 3.901182E+00 | loss scale: 1.0 | grad norm: 25.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:44:14][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       36/      50 | consumed samples:         4608 | elapsed time per iteration (ms): 9929.0/9876.9 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 764.5/768.6 | tokens per GPU (tokens/s/GPU): 13200.9/13272.0 | learning rate: 1.956193E-06 | global batch size:   128 | lm loss: 3.587636E+00 | loss scale: 1.0 | grad norm: 23.282 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:44:23][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       37/      50 | consumed samples:         4736 | elapsed time per iteration (ms): 9859.8/9876.4 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.9/768.7 | tokens per GPU (tokens/s/GPU): 13293.5/13272.6 | learning rate: 1.703271E-06 | global batch size:   128 | lm loss: 3.560862E+00 | loss scale: 1.0 | grad norm: 22.178 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:44:33][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       38/      50 | consumed samples:         4864 | elapsed time per iteration (ms): 9847.4/9875.6 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.8/768.7 | tokens per GPU (tokens/s/GPU): 13310.3/13273.7 | learning rate: 1.464466E-06 | global batch size:   128 | lm loss: 3.469835E+00 | loss scale: 1.0 | grad norm: 20.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:44:43][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       39/      50 | consumed samples:         4992 | elapsed time per iteration (ms): 9856.4/9875.1 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.1/768.8 | tokens per GPU (tokens/s/GPU): 13298.2/13274.3 | learning rate: 1.240801E-06 | global batch size:   128 | lm loss: 3.448598E+00 | loss scale: 1.0 | grad norm: 19.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:44:53][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       40/      50 | consumed samples:         5120 | elapsed time per iteration (ms): 9994.1/9878.2 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 759.5/768.5 | tokens per GPU (tokens/s/GPU): 13115.0/13270.1 | learning rate: 1.033233E-06 | global batch size:   128 | lm loss: 3.460013E+00 | loss scale: 1.0 | grad norm: 20.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:45:03][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       41/      50 | consumed samples:         5248 | elapsed time per iteration (ms): 9845.3/9877.4 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 771.0/768.6 | tokens per GPU (tokens/s/GPU): 13313.1/13271.2 | learning rate: 8.426520E-07 | global batch size:   128 | lm loss: 3.254830E+00 | loss scale: 1.0 | grad norm: 18.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:45:13][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       42/      50 | consumed samples:         5376 | elapsed time per iteration (ms): 9850.7/9876.7 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.6/768.6 | tokens per GPU (tokens/s/GPU): 13305.8/13272.1 | learning rate: 6.698730E-07 | global batch size:   128 | lm loss: 3.104122E+00 | loss scale: 1.0 | grad norm: 16.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:45:23][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       43/      50 | consumed samples:         5504 | elapsed time per iteration (ms): 9850.7/9876.1 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.6/768.7 | tokens per GPU (tokens/s/GPU): 13305.8/13272.9 | learning rate: 5.156363E-07 | global batch size:   128 | lm loss: 3.086677E+00 | loss scale: 1.0 | grad norm: 16.213 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:45:33][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       44/      50 | consumed samples:         5632 | elapsed time per iteration (ms): 9855.9/9875.6 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.2/768.7 | tokens per GPU (tokens/s/GPU): 13298.8/13273.6 | learning rate: 3.806023E-07 | global batch size:   128 | lm loss: 3.004008E+00 | loss scale: 1.0 | grad norm: 15.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:45:42][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       45/      50 | consumed samples:         5760 | elapsed time per iteration (ms): 9861.2/9875.2 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.8/768.7 | tokens per GPU (tokens/s/GPU): 13291.7/13274.0 | learning rate: 2.653493E-07 | global batch size:   128 | lm loss: 3.031956E+00 | loss scale: 1.0 | grad norm: 14.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:45:52][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       46/      50 | consumed samples:         5888 | elapsed time per iteration (ms): 9855.7/9874.8 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.2/768.8 | tokens per GPU (tokens/s/GPU): 13299.1/13274.5 | learning rate: 1.703709E-07 | global batch size:   128 | lm loss: 2.896887E+00 | loss scale: 1.0 | grad norm: 15.230 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:46:02][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       47/      50 | consumed samples:         6016 | elapsed time per iteration (ms): 9869.2/9874.7 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.1/768.8 | tokens per GPU (tokens/s/GPU): 13280.9/13274.7 | learning rate: 9.607360E-08 | global batch size:   128 | lm loss: 2.813146E+00 | loss scale: 1.0 | grad norm: 13.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:46:12][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       48/      50 | consumed samples:         6144 | elapsed time per iteration (ms): 9858.2/9874.3 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 770.0/768.8 | tokens per GPU (tokens/s/GPU): 13295.8/13275.1 | learning rate: 4.277569E-08 | global batch size:   128 | lm loss: 2.922252E+00 | loss scale: 1.0 | grad norm: 13.227 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:46:22][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       49/      50 | consumed samples:         6272 | elapsed time per iteration (ms): 9859.5/9874.0 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.9/768.8 | tokens per GPU (tokens/s/GPU): 13294.0/13275.5 | learning rate: 1.070538E-08 | global batch size:   128 | lm loss: 2.898083E+00 | loss scale: 1.0 | grad norm: 14.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:46:32][rank-7/8][INFO ] [--------trainer.py:2578] :  iteration       50/      50 | consumed samples:         6400 | elapsed time per iteration (ms): 9869.4/9873.9 | hip mem usage/free/total/usage_ratio: 118.03GB/73.96GB/191.98GB/61.48% | throughput per GPU (TFLOP/s/GPU): 769.1/768.8 | tokens per GPU (tokens/s/GPU): 13280.7/13275.7 | learning rate: 0.000000E+00 | global batch size:   128 | lm loss: 2.938138E+00 | loss scale: 1.0 | grad norm: 14.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
[20251211 08:46:32][rank-0/8][DEBUG] [-----------utils.py:385] : [after training is done] datetime: 2025-12-11 08:46:32 
[NODE-0(tw030)] [INFO] primus launcher exited with code 0